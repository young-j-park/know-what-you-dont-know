<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Know What You Don't Know | PRM Calibration</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>üéØ Know What You Don't Know</h1>
        <p class="subtitle">Uncertainty Calibration of Process Reward Models</p>
        <p class="authors">Young-Jin Park, Kristjan Greenewald, Kaveh Alim, Hao Wang, Navid Azizan</p>
        <p class="institution">MIT & MIT-IBM Watson AI Lab & Red Hat AI Innovation | NeurIPS 2025</p>
    
         <!-- Resource Buttons -->
        <div class="header-buttons">
            <a href="https://arxiv.org/abs/2506.09338" class="header-btn btn-arxiv">
                <span class="btn-icon">üìù</span>
                <span class="btn-text">arXiv</span>
            </a>
            <a href="https://github.com/young-j-park/prm-calibration" class="header-btn btn-code">
                <span class="btn-icon">üíª</span>
                <span class="btn-text">Code</span>
            </a>
            <a href="https://huggingface.co/datasets/young-j-park/prm_calibration" class="header-btn btn-data">
                <span class="btn-icon">üìä</span>
                <span class="btn-text">Dataset</span>
            </a>
        </div>
    
    </header>

    <nav>
        <a href="#overview">Overview</a>
        <a href="#calibration-challenge">Challenge</a>
        <a href="#innovation">Methods</a>
        <a href="#results">Results</a>
    </nav>

    <main>
        <section id="hero">
            <div class="hero-content">
                <div class="stat-box">
                    <h3>The Problem</h3>
                    <p>AI spends equal effort on easy and hard problems</p>
                </div>
                <div class="stat-box">
                    <h3>üí° Our Solution</h3>
                    <p>Teach AI to know when to think harder</p>
                </div>
                <div class="stat-box">
                    <h3>‚ö° The Result</h3>
                    <p>Up to 75% reduction in computation, with comparable performance</p>
                </div>
            </div>
        </section>

        <section id="overview">
            <h2>Why This Matters</h2>
            <p class="lead">
                Imagine a student who spends 30 minutes on every test question‚Äîwhether 
                it's "2+2" or a complex calculus proof. Current AI systems often work this way.
            </p>
            
            <div class="video-container">
                <video controls loop muted playsinline>
                    <source src="assets/videos/naive_easy.MP4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p class="caption">Current approach: Fixed computation regardless of difficulty</p>
            </div>

            <p class="tagline"><strong>We taught them to "think smarter not harder".</strong></p>
            
            <div class="figure motivation-figure">
                <img src="assets/images/motivation.png" alt="Easy vs Difficult Problem Comparison">
                <p class="caption">Our approach: Adaptive computation based on problem difficulty</p>
            </div>
        </section>

        <section id="calibration-challenge">
            <h2>The Calibration Challenge</h2>
            
            <p class="lead">
                Off-the-shelf PRMs lack calibration guarantees because their training is inherently 
                tied to a specific policy model. They learn from reasoning paths generated by one 
                particular model (e.g., Qwen-Math-72B-Instruct), binding their accuracy to that model's 
                unique capabilities.
            </p>

            <div class="policy-comparison">
                <div class="policy-item">
                    <img src="assets/images/trained_policy.png" alt="Strong model used for PRM training">
                    <p class="policy-label">Strong Model<br><span class="sublabel">Often used for PRM Training</span></p>
                </div>
                
                <div class="vs-divider">
                    <span>VS</span>
                </div>
                
                <div class="policy-item">
                    <img src="assets/images/inference_policy.png" alt="Weak model used for test-time scaling">
                    <p class="policy-label">Weak Model<br><span class="sublabel">Often used for Test-Time Scaling</span></p>
                </div>
            </div>

            <div class="challenge-explanation">
                <h3>üîç The Root Problem</h3>
                <p>
                    The issue stems from the autoregressive nature of language models, where sequence 
                    generation is policy-dependent. The probability of future tokens œÄ<sub>Œ∏</sub>(x<sub>t+1:T</sub> | x<sub>0:t</sub>) 
                    is conditioned on the model's parameters Œ∏. Consequently, <strong>a PRM is only 
                    calibrated to the statistical patterns of the policy it was trained with</strong>.
                </p>
                
                <div class="mismatch-box">
                    <h4>‚ö†Ô∏è Distributional Mismatch</h4>
                    <p>
                        When a PRM trained on a highly capable 72B model is paired with a weaker 1B model, 
                        it overestimates success probability. The PRM expects the stronger model's performance 
                        and cannot account for the weaker model's higher tendency to make errors on complex 
                        logical steps. This results in <strong>inflated and unreliable confidence scores</strong>.
                    </p>

                    <div class="error-histograms">
                        <div class="histogram-item">
                            <img src="assets/images/err_histogram_plot_uncalibrated_QwenPRM-7B_math500.png" 
                                 alt="QwenPRM-7B calibration error histogram on MATH500">
                            <p class="caption">
                                <strong>QwenPRM-7B on MATH500 (in-distribution):</strong> 
                                Histogram shows estimation errors between PRM predictions and ground-truth 
                                success rates. Positive values (right side) indicate overestimation. 
                                Distribution skews right, particularly for weaker models like Llama-1B.
                            </p>
                        </div>
                        
                        <div class="histogram-item">
                            <img src="assets/images/err_histogram_plot_uncalibrated_QwenPRM-72B_aimes.png" 
                                 alt="QwenPRM-72B calibration error histogram on AIME">
                            <p class="caption">
                                <strong>QwenPRM-72B on AIME24-25 (out-of-distribution):</strong> 
                                Even larger models show severe miscalibration on challenging problems. 
                                Peak near 1.0 indicates systematic overconfidence, especially for 
                                weaker completion models.
                            </p>
                        </div>
                    </div>
                    
                    <p class="key-insight">
                        <strong>Key Insight:</strong> PRMs consistently overestimate success probabilities. 
                        Miscalibration is particularly severe for (1) weaker models and (2) challenging, 
                        out-of-distribution problems.
                    </p>
                </div>
            </div>

            <div class="why-calibrate">
                <h3>üí° Why Calibrate PRMs?</h3>
                <p>
                    While calibration isn't required for simple ranking tasks (where any monotonic 
                    transformation preserves order), calibrated probabilities are essential for:
                </p>
                <ul class="calibration-benefits">
                    <li><strong>Interpretability:</strong> Understanding true confidence levels</li>
                    <li><strong>Safety Monitoring:</strong> Systematic detection of uncertain predictions</li>
                    <li><strong>Efficient Budget Allocation:</strong> Enabling instance-adaptive scaling</li>
                </ul>
            </div>
        </section>

        <section id="innovation">
            <h2>Instance-Adaptive Scaling with Calibrated PRMs</h2>
            
<div class="innovation-flow">
                <!-- Calibrated Confidence Box -->
            <div class="calibration-box">
                <h3>üìä Calibrated Confidence</h3>
                <p>
                    We use quantile regression to fix AI overconfidence, 
                    providing reliable uncertainty estimates with confidence intervals.
                </p>
                
                <div class="prm-diagram">
                    <img src="assets/images/prm.jpg" alt="PRM Calibration Process">
                    <p class="caption">
                        <strong>From Overconfident to Calibrated:</strong> Our method transforms 
                        existing PRMs (which overestimate with reward 0.95) into calibrated models 
                        that provide uncertainty quantification through quantile predictions 
                        (10%, 50%, 90% confidence intervals).
                    </p>
                </div>
            </div>

            <!-- Smart Allocation Box -->
            <div class="allocation-box">
                <h3>üß† Smart Allocation</h3>
                <p>
                    IAS dynamically adjusts computational effort with mathematical guarantees, 
                    allocating resources based on problem difficulty.
                </p>
                
                <div class="video-comparison">
                    <div class="video-item">
                        <h3>Easy Problem ‚Üí Quick Decision</h3>
                        <video controls loop muted playsinline>
                            <source src="assets/videos/smart_easy.MP4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <p class="caption">Minimal computation for straightforward problems</p>
                    </div>
                    
                    <div class="video-item">
                        <h3>Hard Problem ‚Üí Extended Reasoning</h3>
                        <video controls loop muted playsinline>
                            <source src="assets/videos/smart_hard.MP4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <p class="caption">More computation allocated to complex problems</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="results">
            <h2>Key Results</h2>
            <h3>Calibration Method Comparison</h3>
            <p class="lead">
                Our quantile regression (QR) approach outperforms traditional calibration baselines 
                (temperature scaling, isotonic regression, histogram binning) across both 
                in-distribution (MATH500) and out-of-distribution (AIME24-25) datasets.
            </p>
            
            <div class="calibration-comparison">
                <div class="comparison-item">
                    <img src="assets/images/brier_scores_errbar_posthoc_QwenPRM-7B_Llama-3-1B-Instruct.png" 
                         alt="Llama-3.2-1B calibration comparison">
                </div>
                <div class="comparison-item">
                    <img src="assets/images/brier_scores_errbar_posthoc_QwenPRM-7B_Llama-3-8B-Instruct.png" 
                         alt="Llama-3.1-8B calibration comparison">
                </div>
                <div class="comparison-item">
                    <img src="assets/images/brier_scores_errbar_posthoc_QwenPRM-7B_Qwen2-Math-7B-Instruct.png" 
                         alt="Qwen2.5-Math-7B calibration comparison">
                </div>
                <div class="comparison-item">
                    <img src="assets/images/brier_scores_errbar_posthoc_QwenPRM-7B_DeepSeek-R1-Distill-Qwen-7B.png" 
                         alt="DeepSeek-R1-Distill-Qwen-7B calibration comparison">
                </div>
            </div>
            <p class="caption" style="text-align: center; max-width: 900px; margin: 1rem auto;">
                Brier score comparison across calibration methods on MATH500 
                (in-distribution) and AIME24-25 (out-of-distribution). Lower is better. Our QR method 
                (purple) consistently achieves the lowest calibration error, with particularly strong 
                improvements for weaker models and on challenging out-of-distribution problems.
            </p>
            <!-- Add your figures here -->
            <div class="figure">
                <img src="assets/images/main_results.png" alt="Calibration Results">
                <p class="caption">The proposed IAS strategy reduces inference costs while maintaining final answer accuracy, utilizing less compute on more confident problems as desired.</p>
            </div>
        </section>

        <!-- <section id="resources">
            <h2>Dive Deeper</h2>
            <div class="button-group">
                <a href="https://github.com/young-j-park/prm-calibration" class="btn btn-primary">
                    üìÇ GitHub Code
                </a>
                <a href="https://arxiv.org/abs/2506.09338" class="btn btn-secondary">
                    üìÑ Read Paper
                </a>
                <a href="https://huggingface.co/datasets/young-j-park/prm_calibration" class="btn btn-tertiary">
                    üìä Access Datasets
                </a>
            </div>
        </section> -->

        <section id="citation">
            <h2>Citation</h2>
            <pre><code>@inproceedings{park2025prmcalibration,
  title={Know What You Don't Know: Uncertainty Calibration of Process Reward Models},
  author={Park, Young-Jin and Greenewald, Kristjan and Alim, Kaveh and Wang, Hao and Azizan, Navid},
  journal={arXiv preprint arXiv:2506.09338},
  year={2025}
}</code></pre>
        </section>
    </main>

    <footer>
        <p>¬© 2025 MIT & MIT-IBM Watson AI Lab | NeurIPS 2025</p>
        <p>
            <a href="mailto:yjpark0105@gmail.com">Contact</a>
        </p>
    </footer>
    <script>
        // Video autoplay on scroll
        const videos = document.querySelectorAll('video');
        
        const observerOptions = {
            root: null,
            threshold: 0.5, // Play when 50% of video is visible
            rootMargin: '0px'
        };
        
        const videoObserver = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                const video = entry.target;
                if (entry.isIntersecting) {
                    video.play();
                } else {
                    video.pause();
                }
            });
        }, observerOptions);
        
        videos.forEach(video => {
            videoObserver.observe(video);
        });
    </script>
</body>
</html>