<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Know What You Don't Know | PRM Calibration</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>üéØ Know What You Don't Know</h1>
        <p class="subtitle">Uncertainty Calibration of Process Reward Models</p>
        <p class="authors">Young-Jin Park, Kristjan Greenewald, Kaveh Alim, Hao Wang, Navid Azizan</p>
        <p class="institution">MIT & MIT-IBM Watson AI Lab | NeurIPS 2025</p>
    </header>

    <nav>
        <a href="#overview">Overview</a>
        <a href="#results">Results</a>
        <a href="https://arxiv.org/abs/2506.09338">Paper</a>
        <a href="https://github.com/young-j-park/prm-calibration">Code</a>
    </nav>

    <main>
        <section id="hero">
            <div class="hero-content">
                <div class="stat-box">
                    <h3>The Problem</h3>
                    <p>AI spends equal effort on easy and hard problems</p>
                </div>
                <div class="stat-box">
                    <h3>üí° Our Solution</h3>
                    <p>Teach AI to know when to think harder</p>
                </div>
                <div class="stat-box">
                    <h3>‚ö° The Result</h3>
                    <p>Up to 75% reduction in computation, with comparable performance</p>
                </div>
            </div>
        </section>

        <section id="overview">
            <h2>Why This Matters</h2>
            <p class="lead">
                Imagine a student who spends 30 minutes on every test question‚Äîwhether 
                it's "2+2" or a complex calculus proof. Current AI systems often work this way.
            </p>
            
            <div class="video-container">
                <video controls loop muted playsinline>
                    <source src="assets/videos/naive_easy.MP4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p class="caption">Current approach: Fixed computation regardless of difficulty</p>
            </div>

            <p class="tagline"><strong>We taught them to "think smarter not harder".</strong></p>
            
            <div class="figure motivation-figure">
                <img src="assets/images/motivation.png" alt="Easy vs Difficult Problem Comparison">
                <p class="caption">Our approach: Adaptive computation based on problem difficulty</p>
            </div>
        </section>

        <section id="calibration-challenge">
            <h2>The Calibration Challenge</h2>
            
            <p class="lead">
                Off-the-shelf PRMs lack calibration guarantees because their training is inherently 
                tied to a specific policy model. They learn from reasoning paths generated by one 
                particular model (e.g., Qwen-Math-72B-Instruct), binding their accuracy to that model's 
                unique capabilities.
            </p>

            <div class="policy-comparison">
                <div class="policy-item">
                    <img src="assets/images/trained_policy.png" alt="Strong model used for PRM training">
                    <p class="policy-label">Strong Model<br><span class="sublabel">Often used for PRM Training</span></p>
                </div>
                
                <div class="vs-divider">
                    <span>VS</span>
                </div>
                
                <div class="policy-item">
                    <img src="assets/images/inference_policy.png" alt="Weak model used for test-time scaling">
                    <p class="policy-label">Weak Model<br><span class="sublabel">Often used for Test-Time Scaling</span></p>
                </div>
            </div>

            <div class="challenge-explanation">
                <h3>üîç The Root Problem</h3>
                <p>
                    The issue stems from the autoregressive nature of language models, where sequence 
                    generation is policy-dependent. The probability of future tokens œÄ<sub>Œ∏</sub>(x<sub>t+1:T</sub> | x<sub>0:t</sub>) 
                    is conditioned on the model's parameters Œ∏. Consequently, <strong>a PRM is only 
                    calibrated to the statistical patterns of the policy it was trained with</strong>.
                </p>
                
                <div class="mismatch-box">
                    <h4>‚ö†Ô∏è Distributional Mismatch</h4>
                    <p>
                        When a PRM trained on a highly capable 72B model is paired with a weaker 1B model, 
                        it overestimates success probability. The PRM expects the stronger model's performance 
                        and cannot account for the weaker model's higher tendency to make errors on complex 
                        logical steps. This results in <strong>inflated and unreliable confidence scores</strong>.
                    </p>

                    <div class="error-histograms">
                        <div class="histogram-item">
                            <img src="assets/images/err_histogram_plot_uncalibrated_QwenPRM-7B_math500.png" 
                                 alt="QwenPRM-7B calibration error histogram on MATH500">
                            <p class="caption">
                                <strong>QwenPRM-7B on MATH500 (in-distribution):</strong> 
                                Histogram shows estimation errors between PRM predictions and ground-truth 
                                success rates. Positive values (right side) indicate overestimation. 
                                Distribution skews right, particularly for weaker models like Llama-1B.
                            </p>
                        </div>
                        
                        <div class="histogram-item">
                            <img src="assets/images/err_histogram_plot_uncalibrated_QwenPRM-72B_aimes.png" 
                                 alt="QwenPRM-72B calibration error histogram on AIME">
                            <p class="caption">
                                <strong>QwenPRM-72B on AIME24-25 (out-of-distribution):</strong> 
                                Even larger models show severe miscalibration on challenging problems. 
                                Peak near 1.0 indicates systematic overconfidence, especially for 
                                weaker completion models.
                            </p>
                        </div>
                    </div>
                    
                    <p class="key-insight">
                        <strong>Key Insight:</strong> PRMs consistently overestimate success probabilities. 
                        Miscalibration is particularly severe for (1) weaker models and (2) challenging, 
                        out-of-distribution problems.
                    </p>
                </div>
            </div>

            <div class="why-calibrate">
                <h3>üí° Why Calibrate PRMs?</h3>
                <p>
                    While calibration isn't required for simple ranking tasks (where any monotonic 
                    transformation preserves order), calibrated probabilities are essential for:
                </p>
                <ul class="calibration-benefits">
                    <li><strong>Interpretability:</strong> Understanding true confidence levels</li>
                    <li><strong>Safety Monitoring:</strong> Systematic detection of uncertain predictions</li>
                    <li><strong>Efficient Budget Allocation:</strong> Enabling instance-adaptive scaling</li>
                </ul>
            </div>
        </section>

        <section id="innovation">
            <h2>Instance-Adaptive Scaling</h2>
            
            <div class="two-column">
                <div>
                    <h3>üìä Calibrated Success Estimate</h3>
                    <p>We use quantile regression to fix process reward models (PRMs)' overconfidence, 
                    providing reliable success probability estimates.</p>
                </div>
                <div>
                    <h3>üß† Smart Allocation</h3>
                    <p>Instance-adaptive scaling (IAS) dynamically adjusts computational effort with 
                    mathematical guarantees.</p>
                </div>
            </div>

            <div class="video-comparison">
                <div class="video-item">
                    <h3>Easy Problem ‚Üí Quick Decision</h3>
                    <video controls loop muted playsinline>
                        <source src="assets/videos/smart_easy.MP4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p class="caption">Minimal computation for straightforward problems</p>
                </div>
                
                <div class="video-item">
                    <h3>Hard Problem ‚Üí Extended Reasoning</h3>
                    <video controls loop muted playsinline>
                        <source src="assets/videos/smart_hard.MP4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p class="caption">More computation allocated to complex problems</p>
                </div>
            </div>
        </section>

        <section id="results">
            <h2>Key Results</h2>
            <div class="results-grid">
                <div class="result-card">
                    <h3>70-90%</h3>
                    <p>Calibration Error Reduction</p>
                </div>
                <div class="result-card">
                    <h3>50%</h3>
                    <p>Compute Savings</p>
                </div>
                <div class="result-card">
                    <h3>‚úì</h3>
                    <p>Performance Maintained</p>
                </div>
            </div>
            <!-- Add your figures here -->
            <div class="figure">
                <img src="assets/images/main_results.png" alt="Calibration Results">
                <p class="caption">Figure: Calibration improvement across models</p>
            </div>
        </section>

        <section id="resources">
            <h2>Dive Deeper</h2>
            <div class="button-group">
                <a href="https://github.com/young-j-park/prm-calibration" class="btn btn-primary">
                    üìÇ GitHub Code
                </a>
                <a href="https://arxiv.org/abs/2506.09338" class="btn btn-secondary">
                    üìÑ Read Paper
                </a>
                <a href="https://huggingface.co/datasets/young-j-park/prm_calibration" class="btn btn-tertiary">
                    üìä Access Datasets
                </a>
            </div>
        </section>

        <section id="citation">
            <h2>Citation</h2>
            <pre><code>@inproceedings{park2025calprm,
  title={Know What You Don't Know: Uncertainty Calibration of Process Reward Models},
  author={Park, Young-Jin and Greenewald, Kristjan and Alim, Kaveh and Wang, Hao and Azizan, Navid},
  journal={arXiv preprint arXiv:2506.09338},
  year={2025}
}</code></pre>
        </section>
    </main>

    <footer>
        <p>¬© 2025 MIT & MIT-IBM Watson AI Lab | NeurIPS 2025</p>
        <p>
            <a href="mailto:contact@example.com">Contact</a> | 
            <a href="https://twitter.com/yourhandle">Twitter</a>
        </p>
    </footer>
    <script>
        // Video autoplay on scroll
        const videos = document.querySelectorAll('video');
        
        const observerOptions = {
            root: null,
            threshold: 0.5, // Play when 50% of video is visible
            rootMargin: '0px'
        };
        
        const videoObserver = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                const video = entry.target;
                if (entry.isIntersecting) {
                    video.play();
                } else {
                    video.pause();
                }
            });
        }, observerOptions);
        
        videos.forEach(video => {
            videoObserver.observe(video);
        });
    </script>
</body>
</html>